## 운영체제

### CH2 운영체제 구조

**_2.1 운영체제 서비스_**

**_2.2 사용자와 운영체제 인터페이스_**

**_2.3 시스템 콜_**

**_2.4 시스템 서비스_**

**_2.5 링커와 로더_**

**_2.6 응용 프로그램이 운영체제마다 다른 이유_**

**_2.7 운영체제 설계 및 구현_**

**_2.8 운영체제 구조_**

**_2.9 운영체제 빌딩과 부팅_**

**_2.10 운영체제 디버깅_**

### CH3 프로세스

**_3.1 프로세스 개념_**

**_3.2 프로세스 스케줄링_**

**_3.3 프로세스에 대한 연산_**

**_3.4 프로세스간 통신_**

**_3.5 공유 메모리 시스템에서의 프로세스 간 통신_**

**_3.6 메시지 전달 시스템에서의 프로세스 간 통신_**

**_3.7 IPC 시스템의 사례_**

**_3.8 클라이언트 서버 환경에서 통신_**

### CH4 스레드와 병행성(Concurrency)

**_4.1 개요_**

**_4.2 다중 코어 프로그래밍_**

**_4.3 다중 스레드 모델_**

**_4.4 스레드 라이브러리_**

**_4.5 암묵적 스레딩_**

**_4.6 스레드와 관련된 문제들_**

**_4.7 운영체제 사례_**

### CH5 CPU 스케줄링

**_5.1 기본 개념_**

**_5.2 스케줄링 기준_**

**_5.3 스케줄링 알고리즘_**

**_5.4 스레드 스케줄링_**

**_5.5 다중 처리기 스케줄링_**

**_5.6 실시간 CPU 스케줄링_**

**_5.7 운영체제 사례들_**

**_5.8 알고리즘의 평가_**

### CH6 동기화 도구들

**_6.1 배경_**

**_6.2 임계구역 문제_**

**_6.3 Peterson의 해결안_**

**_6.4 동기화를 위한 하드웨어 지원_**

**_6.5 Mutex Locks_**

**_6.6 세마포_**

**_6.7 모니터_**

**_6.8 라이브니스_**

**_6.9 평가_**

### CH7 동기화 예제

**_7.1 고전적인 동기화 문제들_**

**_7.2 커널 안에서의 동기화_**

**_7.3 POSIX 동기화_**

**_7.4 Java에서의 동기화_**

**_7.5 대체 방안들_**

### CH8 교착 상태

**_8.1 시스템 모델_**

**_8.2 다중 스레드 응용에서의 교착 상태_**

**_8.3 교착 상태 특성_**

**_8.4 교착 상태 처리 방법_**

**_8.5 교착 상태 예방_**

**_8.6 교착 상태 회피_**

**_8.7 교착 상태 탐지_**

**_8.8 교착 상태로부터 회복_**

### CH9 메인 메모리

**_9.1 배경_**

- 메모리 관리 : 운영체제에서 프로세스 실행 중 메모리와 디스크 간의 작업을 관리하는 방

  주 목표는 프로그래밍시 쉽게 메모리를 사용할 수 있도록 하는 것, 메모리를 효율적으로 사용하는 것이고, 메모리를 보호해서 프로세스들이 메모리 영역을 침범하지 않도록 잘 막는 것

  멀티 프로그래밍 환경(하나의 프로세서가 하나의 프로세스를 수행하는 동안 입출력이 완료될 때까지 기다리는 시간을 버리지 말고 다른 프로세스를 처리할 수 있도록 해주는 것 )으로 변화하면서 한정된 메모리를 효율적으로 사용하는 것이 필요했다

  메모리 관리 필요성

  프로세스 실행 전후에 메모리를 할당 및 할당 해제합니다.
  프로세스별로 사용된 메모리 공간을 추적합니다.
  조각화 문제를 최소화합니다.
  메인 메모리의 적절한 활용.
  프로세스를 실행하는 동안 데이터 무결성을 유지합니다.

- Compiling : 우리가 작성한 소스코드(Source Code)를 컴퓨터가 이해할 수 있는 언어(기계어, Object Code)로 변환하는 과정
- Linking : 기계어에서 실행파일로 변환시키는 과정

  소스코드를 기계어로 변환시킨 Object File들과 라이브러리 File들을 연결(링킹)하여 만든 것이 바로 실행가능한 파일이다.

  정적 링킹(static): 라이브러리 파일들을 링킹 과정에서 포함한다. 컴파일 하는 시간(컴파일링 + 링킹)은 단축되고, 해당 코드의 유출을 막을 수 있다. 그러나 공통 라이브러리들도 모두 포함되기에 메모리를 엄청나게 차지한다.

  동적 링킹(dynamic): 공통적으로 사용하는 라이브러리들은 하나에 한 번 올려놓고, 매번 왔다갔다 하면서 사용하는 것. 이때 공통적으로 사용하는 라이브러리들 즉, 동적으로 링킹하는 라이브러리라고 하여 DLL(Dynamic Link Library)라고 한다. 장점은 메모리 적게 사용. 단점은 컴파일 성능 오버헤드 발생

- Loading : 메모리로 데이터를 옮기는 것(프로그램을 실행시켰을 때 .exe에 있는 파일이 메모리에 올라가야 실행되는데 이떄 메모리에 적재하는 것이 로딩)

  Address Map은 위에서부터 stack->, <-heap, data segment(static data), code segment로 되어있다. 이 때 code segment와 data segment는 실행파일에 있는 것을 메모리에 그대로 write한다(로딩). heap과 stack은 프로그램이 실행하면서 커졌다가 줄어든다.

  종류 2 : 동적 적재, 오버레이

  - 동적 적재(Dynamic Loading) : 프로세스 크기 < 메모리 크기

    메모리를 로딩할 떄 당연히 일반적으로 메모리에 한꺼번에 다 로딩하는 것이 일반적인 로딩인데 필요한 루틴이 호출될 때 해당 루틴을 메모리에 적재하는 방식

    메모리가 정말 부족했던 과거에 사용되었던 방법.

    프로세스는 메모리보다 반드시 작아야하고, 한정적인 이 메모리 공간을 효율적으로 사용하기 위해 동적 적재를 사용한다.

    장점 : 필요할 때만 적재되어 코드 양이 많을 때 자주 호출 되지 않는 루틴에 특히 더 효율적, OS의 자원을 필요로 하지 않고 프로그래머의 재량에 따라 구현이 가능

  - 오버레이(Overlays) : 프로세스 크기 > 메모리 크기

    가상메모리를 지원하지 않는 임베디드 시스템에서 사용된다.

    실행 중에 주기억장치의 메모리가 부족하면 불필요한 조각이 있는 곳에 새로운 조각을 중첩하여 적재한다.

    overlay는 프로그램 사용자가 프로그램의 영역을 나누고 통제해야했다. 그러나 가상메모리는 운영체제가 이 모든 것을 관리

- 스와핑(Swapping)

  메모리에 적재한 하나의 프로그램과 디스크에 있는 다른 프로그램의 메모리를 교체하는 기법

  Swap In : 디스크에 있는 프로세스를 메모리로 옮기기

  Swap Out : 메모리에 있는 프로세스를 디스크로 옮기기

  디스크에 있던 것을 메모리에 다시 로딩해야해서 좀 느리다

  교체시 context switch 시간은 오버헤드가 있지만 부족한 메모리에 더 많은 프로세스를 실행할 수 있는 장점

  VM의 페이징 기법으로 발전함

- 주소 바인딩(Address Binding)

  물리적 주소(pyhsical address) : 물리적 메모리에 실제 올라가는 위치. 물리적 메모리의 낮은 주소 영역에는 운영체제가, 높은 주소 영역에는 사용자 프로세스들이 올라간다. 메모리는 저장장치이고, 아주 긴 배열로 생각했을 때 이 배열이 가지는 인덱스 값을 물리적 주소라고 한다. 물리적 주소는 메모리 자체의 인덱스

  논리적 주소(logical address) 또는 가상 주소(virtual address) : 프로그램이 실행을 위해 메모리에 적재된다면 그 프로세스를 위한 독자적인 주소공간이 생김. 이 주소를 논리적 주소, 가상주소라고 한다. 논리적 주소는 각 프로세스마다 독립적으로 할당되며 0번지부터 시작되고, CPU는 이와 같은 논리적 주소에 근거해 명령을 실행한다.

  프로그램이 실행되기 위해서는 프로그램이 물리적 메모리에 올라가있어야하고, cpu가 기계어 명령어 수행하기 위한 논리적 주소를 통해 메모리를 참조하기 위해 해당 논리적 주소가 물리 메모리에 매핑 되어있어야한다.

  프로세스의 논리적 주소를 물리적 메모리 주소로 연결시키는 작업을 address binding이라 한다.

  주소 바인딩 방식

  1. 컴파일 타임 바인딩(Compile time binding) : 물리적 메모리 주소가 프로그램을 컴파일 할 때 결정 되는 방식

     논리적주소와 물리적 메모리 주소가 동일하다

     물리적 메모리 위치를 변경하려면 다시 컴파일 해야함
     이미 다른 프로세스가 메모리를 차지하고 있는 경우를 피하기 위해 하나의 프로세스만을 사용할 때 사용()

  2. 로드 타임 바인딩(Load time binding) : 프로그램의 실행이 시작될 때 물리적 메모리 주소가 결정되는 방식

     loader에 의해 물리적 메모리 주소가 부여되며, 프로그램이 종료될 때까지 물리적 메모리 상의 위치가 고정된다
     (loader란 사용자 프로그램을 메모리에 적재시키는 프로그램)

     결과적으로 논리적 주소와 무리적 메모리 주소는 다르다

     메모리를 참조하는 명령어를 다 변경해주어야해서 메모리 로딩 시간이 매우 길어지고, 이로 인해 현재 사용하지 않음

  3. 실행 시간 바인딩(Execution time binding or Run time binding) : 프로그램이 실행을 시작한 이후에도 프로그램이 위치한 물리적 메모리 상의 주소가 변경될 수 있는 방식

     cpu가 주소를 참조할 때마다 해당 데이터의 물리적 메모리가 어디에 위치해야하는지, 주소 매핑 테이블(address mapping table)을 이용해 바인딩을 점검한다

     실행시간에 바인딩이 이루어지므로, 기준 레지스터와 한계 레지스터를 포함한 MMU라는 하드웨어적인 뒷받침이 되어야한다
     (MMU : 논리적 주소를 물리적 주소로 매핑해주는 하드웨어 장치)

     매번 변환 작업을 수행해야하는 것이 더 오래 걸리는 것 같아보이지만, 하드 웨어 성능이 좋아져서 하드웨어 상의 로직 수행으로 실시간 바인딩을 문제 해도 성능 상의 큰 문제가 없다(오히려 로드의 경우 메모리 로딩시 오버헤드가 커서 사용X)

- MMU의 기법

  CPU가 특정 프로세스의 논리적 주소를 참조하고 싶을 때, MMU 기법은 그 주소값에 기준레지스터의 값을 더해 물리적 주소 값을 얻어낸다

  이 때 기준 레지스터는 재배치 레지스터(relocation register)라고도 부르고, 프로세스의 물리적 메모리 시작 주소를 갖고 있다.

  MMU 기법은 프로그램의 주소 공간이 물리적 메모리의 한 장소에 연속적으로 적재되는 것을 가정하기에, 물리적 메모리 상의 시작 주소(기준 레지스터 값)만 알면 쉽게 주소 변환이 가능하다

  ex) cpu가 논리적 주소 123번에 있는 메모리 요청시 기준 레지스터에 저장된 23000을 더해 23123 물리적 메모리 주소 내용을 참조하게 한다.

  context switch에서 수행중인 프로세스가 변경 될 때, 재배치 레지스터의 값을 그 프로세스에 해당하는 값으로 재설정해준다.

  다중 프로그래밍 환경에서는 물리적 메모리 안에 여러 개의 프로세스가 동시에 올라가있는 경우가 대부분. 위으 MMU 방식을 사용했을 경우 논리적 주소 값 + 재배치 레지스터 값이 다른 프로세스의 주소 공간을 침범하는 경우가 생길 수 있다. 이를 방지하기 위해 한계 레지스터를 사용한다.
  이름 처럼 프로세스가 자신의 주소 공간을 넘는 메모리를 참조하는지 체크할 때 사용한다. 따라서 cpu에서 현재 수행 중인 프로세스의 논리적 주소의 최대 값(=프로세스 크기)을 담고 있다. CPU가 요청한 논리적 주소 값이 한계 레지스터 값 이내라면 재배치 레지스터 값을 더해 물리적 위치에 접근하게 되고, 크다면 트랩이 발생

**_9.2 연속 메모리 할당_**

프로세스를 메모리에 연속적으로 할당하는 기법 - 할당과 제거를 반복하다보면 Scattered Holes가 생겨나고 이로 인한 외부 단편화 발생으로 현재는 사용X

- 단편화

  - 외부 단편회(external fragmentation) : 총 공간을 계산했을 때 요청을 만족할만한 충분한 메모리가 있음에도, 가능한 공간이 연속적이지 않을 때(저장 공간이 여러개의 작은 hole로 조각조각 나있어서) 실제로 할당할 수 없는 현상

    - compaction : 비어있는 공간을 연속적인 공간으로 만들고 움직이는 작업 - 하지만 옮기는 과정에서 임시로 HD에 저장해두고, I/O problem.. 발생

  - 내부 단편화(internal fragmentation) : 메모리를 할당 할 떄 프로세스가 필요한 양 보다 더 큰 메모리가 할당 되어서 프로세스에서 사용하는 메모리 공간이 낭비되는 현상. 페이징을 적용하면 외부단편화가 발생하지만, 외부단편화에 비해 메모리를 거의 100% 가깝게 쓸 수 있다(낭비 줄임)

외부 단편화의 해결 방법

- 통합 기법 : 하나의 작업 완료 후 그 사용 영역이 다른 비어있는 분할 공간과 인접해 있는지 점검하여 만약 인접해 있다면 두 개의 빈 분할 공간을 하나로 통합하여 효율성을 높이는 작업
- 압축 기법(compaction) : 주기억 장치 내 분산되어있는 단편화된 비어있는 공간들을 통합하여 하나의 커다란 빈 공간을 만드는 작업 = 가비지 컬렉션 작업이라고도 함. 비용이 많이 들어 정해진 주기에 따라 실행
- 배치 전략 : 배치를 잘 하는 방식을 이용하여 단편화의 발생 가능성을 최대한 줄이는 방식(최초 적합, 최적 적합, 최악 적합)

  가능한 holes에서 하나의 남는 공간을 선택하는 방법(가변 분할 - 프로세스 크기별로 메모리 할당하기)

  1. 최초 적합(First Fit) : 남는 메모리를 순차적으로 앞에서부터 탐색하다가 가장 최초로 발견되는 hole에 할당하기
  2. 최적 적합(Best Fit) : 가장 외부 단편화가 작게 생기게 하는 공간에 할당하기. 가급적으로 남는 자투리 공간 가장 적게 만들 수 있는 곳 선택
  3. 최악 적합(Worst Fit) : holes들 중에서 가장 큰 공간에 넣는 것. 자투리를 크게 만들어야 다른 프로세스가 거기 들어갈 확률이 크다

  first fit과 best fit은 속도나 메모리사용률 측면에서 worst fit보다 좋은 것으로 시뮬레이션에서 나타남.
  그러나 알고리즘적으로는 first fit이 우수할 수 있다

  50퍼센트 규칙 - N개의 블럭이 할당되었을 때 0.5개의 블록이 단편화 때문에 손실될 수 있다. 이것은 기억 장치의 1/3이 쓸 수 없다는 것

- 페이징 기법 사용 : 고정 길이 방식

내부 단편화의 해결 방법

- 세그멘테이션(secmentation) : 가변 길이 방식의 대표 유형
- 메모리 풀 : 동적 할당 방식 중 하나로 미리 필요한 만큼 할당 받아서 만들어 둔다

**_9.3 페이징_**

페이징 : 논리주소의 고정된 페이지(Page)라고 불리는 블록들로 분할 관리하는 기법. 외부 단편화가 절대 발생하지 않는다. 프로세스를 일정한 크기인 페이지(page)로 잘라서 메모리에 적재하는 방식. 지금 인텔 프로세서에서도 쓰이는 방법.

    고정 분할 : 모든 페이지의 크기가 동일 <-> 가변 분할 : 연속할당 방법에서 프로세스들의 크기가 제각각

각각의 페이지는 물리 메모리의 프레임과 매핑한다
패이지 테이블(page table)을 이용해 페이지를 가리키는 논리주소에서 프레임을 가리키는 물리주소로 변환한다

페이지(page) : logical address space를 동일한 크기로 나눈 것
프레임(frame) : pysical memory를 동일한 크기로 나눈 것

**_9.4 페이징 테이블의 구조_**

**_9.5 스와핑_**

**_9.6 사례 : Intel 32비트와 64비트의 구조_**

**_9.7 사례 : ARM 구조_**

### 스케줄링 시스템

스케줄링의 목적 : cpu 활용도를 높여서 여러 프로그램이 짧은 시간안에 처리될 수 있도록 하기 위함

- 배치 처리 시스템 : 큐와 같은 방법으로 앞선 응용 프로그램의 작업이 끝난 이후 이어서 다음 응용 프로그램이 자동으로 실행되는 시스템
  - 문제점 : 실행된 프로그램이 오래 걸릴 경우 대기시간 과도하게 늘어남, 한번에 하나의 작업만 처리하여 멀티 태스킹 불가, 중간에 입력된 작업은 이전 작업이 끝나야만 실행될수 있음
  - 이를 극복하기 위해 멀티 프로그래밍과 시분할 시스템 등장
- 시분할 시스템 : 응용 프로그램이 cpu를 점유하는 시간을 잘게 쪼개어 실행될 수 있도록 하는 시스템
  - 목표 : 프로세스 응답시간을 가능한 짧게 하는 것
- 멀티 태스킹 : 시분할 시스템을 기반으로 하며, 굉장히 짧은 시간 차이는 사람이 인지하지 못하는 점을 활용해 단일 cpu에서 동시에 실행되는것 처럼 보이게 하는 시스템(단일 코어 사용)
- 멀티 프로세싱 : 다중 cpu 코어를 사용하여, 최대한 cpu를 많이 활용하면서 시간 대비 cpu 활용도를 높여 짧은 시간안에 응용 프로그램 실행을 완료함
  - 여러 cpu에 하나의 프로그램을 병렬로 실행해서 속도를 극대화
- 멀티 프로그래밍 : 응용프로그램이 하는 모든 작업이 cpu를 이용하는 것이 아니다. i/o작업에는 cpu가 필요하지 않다(cpu 시간 낭비). 멀티 프로그래밍은 그 동안 다른 응용 프로그램의 작업을 하는 것으로 채우는 것.
  - 목표 : cpu 활용도(cpu가 작업을 한 시간/프로스 실행에 걸린 시간)를 최대한 높이는 것

### 프로세스 스케줄링

정의 : 프로세스가 생성되어 실행될 때 필요한 시스템의 여러 자원을 해당 프로세스에게 할당하는 작업.

목적 : 프로세스의 대기시간은 최소화 하고 최대한 공평하게 처리하기 위함. cpu 활용도를 최대화하기 위함

메모리에 여러개의 프로세스를 올려놓고(다중 프로그래밍), cpu의 가동시간을 적절히 나누어(=시분할) 각각의 프로세스에게 분배하여 실행되도록 한다

프로세스의 상태

1. 생성(create) : 프로세스가 생성되는 중
2. 실행(running) : 프로세스가 프로세서를 차지하여 명령어들이 실행되는 중
3. 준비(ready) : 프로세스가 프로세서를 사용하고 있지는 않지만 언제든지 사용할 수 있는 상태로, cpu 할당을 기다리는 중
4. 대기(waiting) : 프로세스가 입출력 완료, 시그널 수신 등 어떤 사건을 기다리고 있는 중
5. 종료(terminated) : 프로세스의 실행이 종료됨

준비 큐(ready queue)는 준비 상태에 있는 프로세스들을 모아놓은 큐.
운영체제는 cpu 스케줄러를 통해 준비큐에 있는 프로세스 중 한 프로세스를 골라 다음에 실행시킨다.
운영체제가 프로세스를 프로세서에 할당하는 것을 dispatch라고 한다.

프로세스 스케줄링 기법

- 선점형 : 운영체제가 강제로 프로세스의 사용권을 통제하는 방식. cpu 사용권을 선점한다. 특정 요건에 따라 각 프로세스의 요청이 있을 때 프로세스에게 분배하는 방식.

  - running -> ready 가능한 시분할 시스템
  - 가장 자원을 필요로 하는 프로세스에게 cpu를 분배하며, 상황에 따라 강제로 회수도 가능
  - 빠른 응답을 요하는 대화식 시분할 시스템에 적합
  - 긴급한 프로세스를 제어 가능

  - 라운드 로빈(Round - Robin, RR) 스케줄링 : FCFS 스케줄링을 기반으로 하여 cpu를 할당하되, 각 프로세는 한번에 쓸 수 있는 cpu 시간 크기(시간 할당량)이 지나면 시간 종료 인터럽트에 의해 cpu를 빼앗기는 방식.

    - 시분할 시스템을 기반으로 함
    - 주로 Priority Scheduling(우선순위 스케줄링)과 결합해 프로세스의 시간 할당량을 조절하는 방식으로 활용
    - FCFS에서 프로세스 하나가 cpu를 독점하는 단점을 방지하지만, context switch의 오버헤드를 감수

  - SRT 스케줄링 (Shortest Remaining Time) : 준비 큐에서 완료까지 남은 cpu요구량이 가장 짧은 것을 먼저 실행시켜주는 방식

    - 실행 도중 남은 실행시간이 더 적은 프로세스가 준비 큐에 들어올 경우, 현재 실행 중인 것을 중단하고 새 프로세스에게 cpu를 할당한다

  - 다단계 큐 스케줄링 (Multi-level Queue) : 프로세스들의 우선순위 개수만큼의 큐를 생성한 후 프로세스들을 해당하는 우선순위 값 큐에 넣고, 높은 우선순위의 큐에 있는 프로세스들 부터 실행한다
    - 우선순위가 낮은 하위 단계의 큐의 작업은 실행 중이더라도 상위 단계 큐에 프로세스가 도착하면 cpu를 뺏긴다

- 비선점형 : 프로세스가 스스로 다음 프로세스에게 자리를 넘겨주는 방식. 이미 할당된 cpu를 다른 프로세스가 강제로 빼앗아 사용할 수 없는 스케줄링 기법(프로세스가 cpu를 할당 받으면 해당 프로세스가 완료될 때 까지 cpu를 사용X. 매우 공정하지만 priority가 높은 프로세스에 대응하기에는 비효율적)

  - FCFS 스케줄링 (First Come First Serve Scheduling) : cpu를 먼저 요청한 프로세스를 먼저 배정한다

    - 배치 처리 시스템에 사용됨

    - convey effect : 커다란 한 프로세스가 끝날 때까지 다른 모든 프로세스들이 기다ㄹ는 현상. 이는 cpu와 장치의 사용률을 낮추기 때문에 최대한 지양

  - SPN 스케줄링 (Shortest Process Next) 또는 Shortest Job First : 준비 큐에서 기다리고 있는 프로세스 중에서 가장 cpu 요구량이 적은 것을 먼저 실행시켜준다.

    - 작업을 시작하기 전에 모든 프로세스의 각 작업에 걸리는 시간을 계산해야한다
    - 평균 응답시간을 최소화할 수 있다
    - 실행시간이 긴 프로세스가 cpu를 할당받지 못하고 계속해서 대기하는 무한 대기 현상이 발생할 수 있다

  - HRRN(Highest Response Ratio Next) : 준비 큐에 있는 프로세스들 중에서 응답률( response ration = (대기시간 + cpu 요구량) / cpu 요구량)이 가장 높은 프로세스에게 높은 우선순위를 주는 방식
    - 수행 시간이 긴 프로세스의 무한 대기 현상을 방지한다

콘보이 현상이란? 콘보이 현상이 발생될 수 있는 cpu 스케줄러 알고리즘은?
콘보이 현상이란 작업 시간이 긴 프로세스가 먼저 큐에 도착해서 다른 프로세스의 실행 시간이 전부 늦춰져 효율성을 떨어뜨리는 현상이다. FCFS(First Come First Start) 스케줄링 알고리즘은 비선점으로, 순차적으로 먼저 큐에 들어온 작업부터 실행하므로 콘보이 현상이 발생할 수 있다.

스케줄러 종류 3가지를 설명하시오
장기 스케줄러/잡 스케줄러 : 디스크와 메모리 사이의 스케줄링을 담당(ready). 레디 큐에 적재하는 스케줄러. I/O bound 중심의 프로세스들만 쭉 적재시키면 입출력을 기다리느라 노는 cpu가 많아지고, cpu bound 중심의 프로세스들만 적재시켜버리면 사용자와 상호적이지 못해 실시간적 의미가 없어진다. 따라서 i/o bound 프로세스와 cpu bound 프로세스의 적절한 비율의 혼합이 필요하다
단기 스케줄러/cpu 스케줄러 : 메모리와 cpu 사이의 스케줄링을 담당(running). 실행이 준비된 프로세스들 중(레디 큐에 있는 프로세스들) 중 하나를 선별해 cpu에 할당

중기 스케줄러/스와퍼 : 여유공간을 마련하기 위해 프로세스를 메모리에서 디스크로 보내는 역할.

컨텍스트 스위칭에 대해서 설명하시오
멀티 프로세스 환경에서 CPU가 어떤 프로세스를 실행하다 인터럽트에 의해 다른 프로세스를 실행해야 할 때 현재 프로세스 정보를 레지스터 등에 저장하고 실행해야할 새로운 프로세스 정보로 변경하게 되는데 이를 컨텍스트 스위칭이라고 합니다

Context Switching이란 인터럽트를 발생시켜 CPU에서 실행중인 프로세스를 중단하고, 다른 프로세스를 처리하기 위한 과정입니다. Context Switching는 현재 실행중인 프로세스의 상태(Context)를 먼저 저장하고, 다음 프로세스를 동작시켜 작업을 처리한 후에 이전에 저장된 프로세스의 상태를 다시 복구합니다. 여기서 인터럽트란 CPU가 프로세스를 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생하여 처리가 필요함을 CPU에게 알리는 것을 말합니다.

스와핑이란 무엇인가
다중 프로그래밍 환경에서 CPU 점유 시간이 끝난 프로세스 메모리를 보조 기억장치로 보내고 다른 프로세스 메모리를 올리는 것을 스왑이라고 합니다.

semaphore = 깃발(옛날 겹치는 기찻길에 걸려있는 깃발 표식)

lock은 0 또는 1인 반면 세마포어는 단순한 변수로 shared data의 개수를 의미. semaphore는 사용가능한 자원의 개수로 초기화됨
사용하면 -1, 반납할 때 +1

- binary semaphore
- counting semaphore
  semaphore 또한 shared data가 되면 안되니까 atomic한 함수를 사용한다(spinlock, intgerrupt disable/enable)
  semaphore 변수 S는 초기화를 제외하면 atomic operation인 wait()와 signal()로만 접근가능한 정수타입의 변수
  함수

wait() : -1
signal() : +1

질문 :
뮤텍스란 무엇인가?
세마포어란 무엇인가?
뮤텍스와 세마포어의 차이는 무엇인가?
세마포어는 뮤텍스가 될 수 있지만 뮤텍스는 세마포어가 될 수 없다.
뮤텍스는 동기화 대상이 1개일 때 사용하고, 세마포어는 동기화 대상이 여러개일 때 사용한다.
뮤텍스는 자원을 소유할 수 있고 책임을 가지지만, 세마포어는 자원을 소유할 수 없다.
뮤텍스는 자원을 소유하고 있는 스레드만이 뮤텍스를 해제할 수 있지만 세마포어는 자원을 소유하지 않는 스레드가 세마포어를 해제할 수 있다.

세마포어와 뮤텍스의 차이에 대해 설명하시오.

semwait와 semsignal 연산에 대해 설명하시오.

- 세마포어는 동작하는 중에 세마포어 변수, semWait연산, semSignal연산을 한다. 세마포어 변수는 정수 값을 가지고, 그 정수 값은 접근할 수 있는 사용자의 최대 허용치이다. semWait()연산은 세마포어 값을 감소시킨다. 만일 값이 음수가 되면 semWait을 호출한 프로세스는 블록된다. 음수가 아니면 프로세스는 계속 수행된다. semSignal()연산은 세마포어 값을 증가한다. 만약 값이 양수가 0이거나 음수이면 semWait()연산에 의해 블록된 프로세스들을 깨운다
  critical section앞에 semWait()연산을 수행하고, critical section 뒤에 semSiganl()연산을 수행한다.

스핀락에 대해 설명하시오.
스핀락(spinlock)은 임계 구역(critical section)에 진입이 불가능할 때 진입이 가능할 때까지 루프를 돌면서 재시도하는 방식으로 구현된 락을 가리킨다. 스핀락이라는 이름은 락을 획득할 때까지 해당 스레드가 빙빙 돌고 있다(spinning)는 것을 의미한다. 스핀락은 busy waiting의 한 종류

세마포어와 모니터의 차이에 대해 설명하시오

데드락이란?
둘 이상의 프로세스가 달느 프로세스가 점유하고 있는 자원을 서로 기다릴 때 무한대기에 빠지는 상황을 의미합니다.
멀티 스레드 개발시 여러 스레드가 하나의 자원을 공유할 경우 데드락 문제가 발생할 수 있습니다.

데드락이 발생하는 필요조건 4가지

1. 상호배제 : 한번에 한 프로세스만이 자원을 사용하도록 하는
2. 점유와 대기 : 프로세스가 할당된 자원을 가진 상태에서 다른 자원을 기다리는
3. 비선점 : 자원들은 그들이 점요하고 있는 프로세스로부터 도중에 해제되지 않음
4. 환형 대기 : 프로세스와 자원들이 원형을 이루어 각 프로세스는 자신에게 할당된 자원을 가지면서 상대방 프로세스의 자원을 상호 요청할 때

대부분의 운영체제에서 교착 상태를 막는 것은 불가능.

1. 예방: 발생 조건 자체를 만족하지 못하게 만듦. sw개발자의 역량
2. 회피: 은행원 알고리즘(모든 자원들의 최대 가능한 할당향으로 시뮬레이션함. 교착상태 가능성을 미리 조사함), Round Robin?
3. 탐지 및 회복: 데드락 발생 자체는 가능. 발생 이후에 이를 인지하고 복구하는 것. 최소 비용으로 중지 시키는 법을 찾도록 한다.

은행원 알고리즘 : 교착상태에 빠질 가능성이 있는지 판단하기 위해 안정상태와 불안전 상태로 나눈다.
은행원 알고리즘에서 운영체제는 안전상태를 유지할 수 있는 요구만을 수락하고 불안전 상태를 초래할 사용자의 요구는 나중에 만족될 수 있을 때 까지 계속 거절. 프로세스가 시작할 떄 프로세스가 필요한 할당할 자원의 갯수를 미리 알아야하고, 오버헤드가 크기 때문에 현재 채택은 하지 않는다

데드락 탐지

데드락 회복

1. 프로세스 또는 스레드를 중지시키기 : 교착 상태 프로세스를 모두 중지하거나 교착 상태가 제거될 때 까지 한

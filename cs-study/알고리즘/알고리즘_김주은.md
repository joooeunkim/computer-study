## 알고리즘

### 시간 복잡도, 공간 복잡도

복잡도는 알고리즘의 성능을 나타내는 척도이다.

복잡도는 시간 복잡도(Time Complexity) 와 공간 복잡도(Space Complexity) 로 나눌 수 있다.

시간 복잡도는 특정한 크기의 입력에 대하여 알고리즘이 얼마나 오래 걸리는지를 의미하고 공간 복잡도는 특정한 크기의 입력에 대하여 알고리즘이 얼마나 많은 메모리를 차지하는지를 의미한다.

동일한 기능을 수행하는 알고리즘이 있다면 일반적으로 복잡도가 낮을수록 좋은 알고리즘이다.

복잡도의 측정으로 우리는 '알고리즘을 위해 필요한 연산의 횟수'로 시간 복잡도를 계산할 수 있고 '알고리즘을 위해 필요한 메모리의 양'으로 공간 복잡도를 계산할 수 있다.

- 시간복잡도

  주로 Big-O 표기법을 사용한다.

  O(N3)을 넘어가면 문제 풀이에서 사용하기 어려운 알고리즘으로 N이 1000개를 넘어가면 5초 이상의 시간이 소요될 것이라고 예상할 수 있다.

  N의 범위가 500인 경우) 시간 복잡도가 O(N3)인 알고리즘을 설계하면 문제 해결 가능
  N의 범위가 2000인 경우) 시간 복잡도가 O(N2)인 알고리즘을 설계하면 문제 해결 가능
  N의 범위가 100,000인 경우) 시간 복잡도가 O(Nlog N)인 알고리즘을 설계하면 문제 해결 가능
  N의 범위가 10,000,000인 경우) 시간 복잡도가 O(N)인 알고리즘을 설계하면 문제 해결 가능
  보통 1억(108)번의 연산당 1초의 시간이 걸린다고 간주한다.

- 공간복잡도

  코딩 테스트에서는 보통 메모리 사용량을 128~512MB로 제한하고 있다. 즉 일반적인 경우 데이터의 개수가 1,000만 단위를 넘어가지 않도록 알고리즘 설계를 해야하고 100만 개 이상의 데이터가 들어갈 수 있는 크기의 배열을 선언하는 경우는 거의 드물다.
  리스트의 크기가 1,000만 단위 이상이라면 자신이 알고리즘을 잘못 설계한 것이 아닌지 확인하는 과정이 필요하다.

---

빅오 표기법

알고리즘의 연산 횟수가 어떻게 최대한 증가하는지 (상한선 기준으로)측정해 알고리즘의 효율성을 표기해주는 표기법.worst-case를 가정한다. 즉, 가장 오래 걸릴 경우, 가장 많은 공간을 필요료 할 경우의 시간 복잡도를 표기한다는 것.

알고리즘의 효율성 : 데이터 개수(n)가 주어졌을 때 덧셈, 뺄셈, 곱셈 같은 기본 연산의 횟수를 의미한다.

빅오 표기법은 보통 알고리즘의 시간 복잡도와 공간 복잡도를 나타내는데 주로 사용 된다. (시간 복잡도는 알고리즘의 시간 효율성을 의미하고, 공간 복잡도는 알고리즘의 공간(메모리) 효율성을 의미한다.)

중요하지 않은 항과, 상수 계수를 제거하면 알고리즘을 이해하는데 방해되는 불필요한 부분을 생각하지 않을 수 있어서 알고리즘에서 중요한 부분인 성장률에 집중할 수 있다.
이렇게 중요하지 않은 항과, 상수 계수를 제거한 표기법을 점근적 표기법(asymptotic notation)이라고 한다.

시간과 공간 복잡도를 나타내는 방법으로는 점근 표기법이라고 해서 빅오(Big-O), 빅오메가(big-Ω),빅세타(big-Θ) 표기법이 있다.

특징

1. 상수항 무시 : 빅오 표기법은 데이터 입력값(n)이 충분히 크다고 가정하고 있고, 알고리즘의 효율성 또한 데이터 입력값(n)의 크기에 따라 영향 받기 때문에 상수항 같은 사소한 부분은 무시한다.
2. 영향력 없는 항 무시 : 빅오 표기법은 데이터 입력값(n)의 크기에 따라 영향을 받기 때문에 가장 영향력이 큰 항에 이외에 영향력이 없는 항들은 무시한다.

O(1) < O(log N) < O(N) < O(N log N) < O(N^2) < O(2^N) < O(N!)

예시

1. O(1) : 스택에서 Push, Pop
2. O(log n) : 이진트리
3. O(n) : for 문
4. O(n log n) : 퀵 정렬(quick sort), 병합정렬(merge sort), 힙 정렬(heap Sort)
5. O(n^2): 이중 for 문, 삽입정렬(insertion sort), 거품정렬(bubble sort), 선택정렬(selection sort)
6. O(2^n) : 피보나치 수열

### 완전 탐색 알고리즘 (Brute Force)

간단히 가능한 모든 경우의 수를 다 체크해서 정답을 찾는 방법

완전 탐색 자체가 알고리즘은 아니기 때문에 완전 탐색 방법을 이용하기 위해서 여러 알고리즘 기법이 이용된다. 주로 이용되는 기법

- 단순 Brute-Force
- 비트마스크(Bitmask)
- 재귀 함수
- 순열 (Permutation)
- BFS / DFS

직관적이어서 이해하기 쉽고 문제의 정확한 결과값을 얻어낼 수 있는 가장 확실하며 기초적인 방법

사용하는 경우

- 입력으로 주어지는 데이터(N)의 크기가 매우 작다. 다른 알고리즘 문제에 비해 완전 탐색 문제는 시간 복잡도가 크기 때문에 ex) 부분집합, 순열-> O(2^N), O(N!) N의 크기가 매우 작다.
- 출력해야 하는 값의 범위가 작아서 입력값 N이 크더라도 역추적할 수 있을 때 사용한다.
- 어떠한 문제의 조건을 고정시켰을 때 풀이가 간단해지는 경우(완전 탐색+그리디)

### DFS와 BFS

- DFS(Depth First Search, 깊이 우선 탐색) : 깊이를 우선적으로 고려하여 모든 정점을 순회하는 알고리즘

  더 이상 갈 수 있는 정점이 존재하지 않을 때까지 정점을 타고 내려간 후에, 갈림길까지 돌아가서 다시 순차적으로 탐색한다.

  - 한 경로로 최대한 깊숙하게 들어가서 탐색한 후 다시 돌아가 다른 경로로 탐색하는 방식
  - 재귀함수, Stack을 이용해 구현
  - 유의할 점 : Stack Overflow (기저조건 잘 설정)
  - 활용 : 백트래킹, 단절선/단절점 찾기, 위상정렬, 사이클 찾기 등

  사이클 확인이 가능

  특징

  - 자기 자신을 호출하는 순환 알고리즘의 형태 를 가지고 있다.
  - 전위 순회(Pre-Order Traversals)를 포함한 다른 형태의 트리 순회는 모두 DFS의 한 종류이다.
  - 이 알고리즘을 구현할 때 가장 큰 차이점은, 그래프 탐색의 경우 어떤 노드를 방문했었는지 여부를 반드시 검사 해야 한다는 것이다. 이를 검사하지 않을 경우 무한루프에 빠질 위험이 있다.

  장점

  1. 현재 경로상의 노드들만 기억하면 되므로, 저장 공간의 수요가 비교적 적음
  2. 목표 노드가 깊은 단계에 있는 경우 해를 빨리 구할 수 있음
  3. 구현이 너비 우선 탐색(BFS) 보다 간단함

  단점

  1. 단순 검색 속도는 너비 우선 탐색(BFS) 보다 느림
  2. 해가 없는 경우에 빠질 가능성이 있음(사전에 임의의 깊이를 지정한 후 탐색하고, 목표 노드를 발견하지 못할 경우 다음 경로를 탐색하도록 함)
  3. 깊이 우선 탐색은 해를 구하면 탐색이 종료되므로, 구한 해가 최단 경로가 된다는 보장이 없음(목표에 이르는 경로가 다수인 경우 구한 해가 최적이 아닐 수 있음)

시간 복잡도

- DFS는 그래프(정점의 수: N, 간선의 수: E)의 모든 간선을 조회한다.
- 인접 리스트로 표현된 그래프: O(N+E)
- 인접 행렬로 표현된 그래프: O(N^2)
- 즉, 그래프 내에 적은 숫자의 간선만을 가지는 희소 그래프(Sparse Graph) 의 경우 인접 행렬보다 인접 리스트를 사용하는 것이 유리하다.

- BFS(Breadth First Search, 너비 우선 탐색) : 가까운 노드부터 탐색하며 모든 정점을 탐색하는 알고리즘

  - 시작 노드에서 시작하여 인접한 노드를 먼저 탐색하는 방식, 여러 경로 동시에 탐색 가능
  - Queue를 이용해 구현
  - 유의할 점 : 메모리 초과 (방문 체크 꼭 해줘야 함)
  - 활용 : 최단경로 찾기, 위상정렬 등

  최단 거리/경로를 계산할 때 사용

  특징

  - 직관적이지 않은 면이 있다.
  - BFS는 시작 노드에서 시작해서 거리에 따라 단계별로 탐색한다고 볼 수 있다.
  - BFS는 재귀적으로 동작하지 않는다.
  - 이 알고리즘을 구현할 때 가장 큰 차이점은, 그래프 탐색의 경우 어떤 노드를 방문했었는지 여부를 반드시 검사 해야 한다는 것이다.
    이를 검사하지 않을 경우 무한루프에 빠질 위험이 있다.
  - BFS는 방문한 노드들을 차례로 저장한 후 꺼낼 수 있는 자료 구조인 큐(Queue)를 사용한다.즉, 선입선출(FIFO) 원칙으로 탐색
  - ‘Prim’, ‘Dijkstra’ 알고리즘과 유사하다.

장점

1. 노드의 수가 적고 깊이가 얕은 경우 빠르게 동작할 수 있다.

2. 단순 검색 속도가 깊이 우선 탐색(DFS)보다 빠름

3. 너비를 우선 탐색하기에 답이 되는 경로가 여러개인 경우에도 최단경로임을 보장한다.

4. 최단경로가 존재한다면 어느 한 경로가 무한히 깊어진다해도 최단경로를 반드시 찾을 수 있다.

단점

1. 재귀호출의 DFS와는 달리 큐에 다음에 탐색할 정점들을 저장해야 하므로 저장공간이 많이 필요하다.
2. 노드의 수가 늘어나면 탐색해야하는 노드 또한 많아지기에 비현실적이다.

시간복잡도

- 인접 리스트로 표현된 그래프: O(N+E)
- 인접 행렬로 표현된 그래프: O(N^2)
- 깊이 우선 탐색(DFS)과 마찬가지로 그래프 내에 적은 숫자의 간선만을 가지는 희소 그래프(Sparse Graph) 의 경우 인접 행렬보다 인접 리스트를 사용하는 것이 유리하다.

### 순열, 조합, 부분집합

- 순열
  - 서로 다른 것들 중 몇 개를 뽑아서 한 줄로 나열하는 것
  - 서로 다른 n개 중 r개를 택하는 순열 nPr = n _ (n-1) _ (n-2) _ ... _ (n-r+1)
  - nPn = n! 이며 10! 이상의 계산은 위험하다.
  - 순열 구현 : 재귀 함수, 비트마스크, next permutation
- 조합
  - 서로 다른 n개의 원소 중 r개를 순서 없이 골라낸 것
  - 서로 다른 n개 중 r개를 택하는 조합 nCr = n! / (n-r)!r!
  - 조합 구현 : 재귀 함수, next permutation
- 부분집합

  - 집합에 포함된 원소들을 선택하는 것
  - 집합의 원소가 n개일 때, 공집합을 포함한 부분집합(멱집합, power set)의 개수는 2N개이다. (각 원소를 포함시키거나 / 포함시키지 않거나)
  - 부분집합 구현 : 재귀 함수, 바이너리 카운팅

- Next Permutation

현재 순열의 상태에서 크기순으로(사전순) 다음에 올 수 있는 순열을 생성해주는 역할

### 백트래킹

백트래킹은 트리 구조를 기반으로 DFS로 깊이 탐색을 진행하면서 각 루트에 대해 조건에 부합하는지 체크(Promising), 만약 해당 트리(나무)에서 조건에 맞지않는 노드는 더 이상 DFS로 깊이 탐색을 진행하지 않고, 가지를 쳐버림 (Pruning)

완전탐색의 아이디어에서 불필요한 분기(Branch) 를 가지치기(Pruning) 하는 것입니다.

정답을 도출하기 전 탐색과정 중에 정답이 될 수 없는 조건에 해당된다면 가지치기하여 효율을 높일 수 있습니다.

backtracking vs dfs

DFS : 완전 탐색을 기본으로 하는 그래프 순회 기법으로 가능한 모든 경로를 탐색한다.

불필요한 경로를 사전에 차단하는 행동이 없다. 따라서 자원 소모가 심하다.

Backtracking: 경로를 찾아가는 도중에 해가 되지 않을 것 같은 경로가 갔다면 더 가지 않고 되돌아온다.

이는 가지치기라고 불린다.

불필요한 경로를 조기 차단하기 때문에 확인해야 하는 경로 수를 줄일 수 있다.

### Divide and Conquer

분할정복 (Divide and Conquer)이란 하나의 문제를 작은 여러개의 문제로 쪼갠 후 재귀적으로 각 문제를 해결한 후 이를 다시 합쳐 원래 문제를 해결하는 방법

Divide and Conquer(분할정복)은 해결하기 힘든 큰 문제를 작은 문제로 분할하여 해결(정복)한 후 병합하는 알고리즘

1. Divide(분할) : 문제를 더 작은 문제들로 분할
2. Conquer(정복) : 분할한 작은 문제들을 해결
3. Combine(병합) : 작은 문제들의 해결법을 병합해 큰 문제의 해결법을 찾는다.

특징

- 분할된 문제는 기존 문제와 성격이 동일하며 단순히 입력 크기만 작아진 것이다.
- 분할된 문제들은 독립적이다.

장점

- Top-down 재귀방식으로 구현하기 때문에 코드가 직관적이다.

- 문제를 나누어 해결한다는 특징상 병렬적으로 문제를 해결할 수 있다.

단점

- 재귀 함수 호츨로 오버헤드가 발생할 수 있다.
- 스택에 다량의 데이터가 보관되는 경우 오버플로우가 발생할 수 있다.
- 재귀적으로 문제를 해결하기 때문에 인풋이 너무 큰 경우 많은 프로그래밍 언어에서 Stack Overflow가 발생할 수 있으며, 이는 메모리의 비효율적 사용을 뜻한다.

예시 - 정렬 알고리즘 중에서 퀵 정렬이나 합병 정렬과 이진 탐색, 고속 푸리에 변환(FFT) 문제, 최솟값(최댓값) 찾기 알고리즘

선택 정렬과 삽입 정렬의 최대 실행시간은 O(n^2)이다. 입력하는 배열의 크기가 크다면 이 알고리즘으로 정렬하는데 매우 오랜 시간이 걸릴 수 있다.

반면 분할정복 알고리즘을 사용하는 합병 정렬의 실행시간은 모든 경우에 대해 O(nlogn)으로 , 퀵 정렬은 최대 O(n^2)이지만 최선이나 평균의 경우 O(nlgn)으로 비교적 빠른 시간을 갖는 것을 볼 수 있다.

### Greedy

미리 정한 기준에 따라서 매번 가장 좋아보이는 답을 선택하는 알고리즘

여러 경우 중 하나를 결정해야할 때마다 가능한 해들 중에서 가장 좋은 해를 선택하고, 선택을 번복하지 않는 방식으로 진행하여 최종적인 해답에 도달. 단, 최적해를 반드시 구한다는 보장이 없기 때문에 증명과정 필요

조건

- 탐욕적 선택 속성(greedy choice property) : 탐욕적으로만 선택을 해도 최적해를 구할 수 있다
- 최적 부분 구조(optimal substructure property) : 부분 문제의 최적 해에서 전체 문제의 최적 해를 만들 수 있다

예시

- 프림(Prim) 알고리즘 : 현재 정점에 연결된 간선들 중 가중치가 작은 간선부터 선택한다.
- 크루스칼(Kruskal) 알고리즘 : 각 단계에서 가중치가 작은 간선부터 선택한다.
- 다익스트라(Dijkstra) 알고리즘 : 현재 정점에서 가장 가까운 정점을 선택한다.
- 분할 가능 배낭 문제

### Dynamic Programming

주어진 문제를 여러 개의 부분 문제들로 나누어 푼 다음, 겹치는 문제의 경우 메모이제이션 기법을 사용하여 주어진 문제를 푼다. 한마디로 분할정복 + 메모이제이션 기법이라고 할 수 있다.

주어진 문제를 풀기 위해서, 문제를 여러 개의 하위 문제(subproblem)로 나누어 푼다음 그것을 결합하여 해결하는 방식.

DP에서는 어떤 부분 문제가 다른 문제를 해결하는데 사용될 수 있어서, 답을 여러번 계산하는 대신 한 번만 계산하고 그 결과를 재활용하는 메모이제이션(Memoization) 기법으로 속도를 향상시킬 수 있다.

조건

- Overlapping Subproblem(중복되는 부분문제) : 주어진 문제는 같은 부분 문제가 여러 번 재사용된다.
- Optimal Substructure(최적 부분구조) : 새로운 부분 문제의 정답을 다른 부분 문제의 정답으로부터 구할 수 있다

구현 방식

1. 메모이제이션을 이용한 DP :
   Top-Down. 반복되는 결과를 메모리에 저장해서 중복 호출 되었을 때 한번더 계산하지 않고 저장된 값을 가져와서 사용. 큰 문제를 방문하고 작은 문제를 호출하여 답을 찾는 방식. 가독성 좋지만 스택 메모리 사용
2. 반복문을 이용한 DP :
   Bottom-Up. 재귀가 필요가 없고, for문을 이용해서 수행. 가장 작은 문제들부터 답을 구해가며 전체 문제의 답을 찾음. 함수를 별개로 부르지 않아 시간과 메모리 절약

DP vs Divide and Conquer :
작은 문제가 중복이 일어나는지 안일으 나는지의 결정적 차이점
분할 정복은 큰 문제를 해결하기 어려워 단지 작은 문제로 나누어 푸는 방법. 특징은 작은 문제에서 반복이 일어나는 부분이 없다.
반면 DP는 작은 문제들이 반복됨(답이 바뀌지 않음)을 이용해, 한번 구한 작은 문제를 재사용하며 풀어나간다.

점화식의 꼴로 나타낼 수 없는 종류의 문제들은 DP를 이용하여 알고리즘을 설계하기 어렵다.

대표적으로 정렬과정을 수학적인 수식으로 더하거나 할 수 없기 때문에 수학적인 점화식으로 만들 수 없고,
따라서 DP로 알고리즘을 설계하기 어렵습니다.

예시

- 0/1 배낭 짐싸기 문제(Knapsack Problem)
- 최장증가수열(LIS, Longest Increasing Subsequence)
- 외판원 순회 문제(TSP, Traveling Salesman Problem)

참조 : https://mangkyu.tistory.com/90

### 정렬

1. 선택 정렬(Selection Sort) : 현재 위치에 들어갈 값을 찾아 정렬하는 배열

   현재 위치에 저장될 값의 크기가 작냐, 크냐에 따라 최소 선택 정렬(Min-Selection Sort 오름차순)와 최대 선택 정렬(Max-Selection Sort 내림차순)로 구분할 수 있다.

   로직

   1. 정렬되지 않은 인덱스의 맨 앞에서부터, 이를 포함한 그 이후 배열값 중 가장 작은 값을 찾는다.
   2. 가장 작은 값을 찾으면, 그 값을 현재 인덱스 값과 바꾼다.
   3. 다음위치에서 위 과정을 반복

   시간 복잡도 : O(n^2)
   공간 복잡도 : O(n)

2. 삽입 정렬(Insertion Sort) : 현재 위치에서 그 이하의 배열들을 비교하여 자신이 들어갈 위치를 찾아, 그 위치에 삽입하는 배열 알고리즘

   로직

   1. 삽입 정렬은 두 번째 인덱스부터 시작한다. 현재 인덱스는 별도의 변수에 저장해주고, 비교 인덱스를 (현재 인덱스 - 1)로 잡는다.
   2. 별도로 저장해 둔 삽입을 위한 변수와, 비교 인덱스의 배열 값을 비교한다.
   3. 삽입 변수의 값이 더 작으면 현재 인덱스로 비교 인덱스의 값을 저장해주고, 비교 인덱스를 -1 하여 비교를 반복한다.
   4. 만약 삽입 변수가 더 크면, 비교 인덱스 +1에 삽입 변수를 저장한다.

   시간 복잡도 : O(n^2) - 최악, o(n) - 최선
   공간 복잡도 : O(n)

3. 버블 정렬(Bubble Sort)

   매번 연속된 두개의 인덱스를 비교하여, 정한 기준의 값을 뒤로 넙겨 정렬하는 방법.

   오름차순으로 정렬하고자 할 경우, 비교시마다 큰 값이 뒤로 이동하여 1바퀴 돌시 가장 큰 값이 맨 뒤에 저장된다.

   맨 마지막에는 비교하는 수들 중 가장 큰 값이 저장되기 때문에, (전체 배열의 크기 - 현재까지 순환 한 바퀴수)만큼만 반복해 주면 된다.

   로직

   1. 버블 정렬은 두 번째 인덱스 부터 시작한다. 현재 인덱스 값과, 바로 이전의 인덱스 값을 비교한다.
   2. 만약 이전 인덱스가 더 크면, 현재 인덱스와 바꿔준다.
   3. 현재 인덱스가 더 크다면, 교환하지 않고 다음 두 연속된 배열값을 확인한다.
   4. 이를 (전체 배열의 크기 - 현재까지 순환한 바퀴 수)만큼 반복한다.

시간 복잡도 : o(n^2)
공간 복잡도 : o(n)

4. 합병 정렬 (Merge Sort)

   Divide and Conquer 방식으로 설계된 알고리즘. 큰 문제를 반으로 쪼개 문제를 해결해나가는 방식으로 분할은 배열의 크기가 1보다 같거나 작을 때 까지 반복

   입력으로 하나의 배열을 받고, 연산 중에 두 개의 배열로 계속 쪼개 나간 뒤, 합치면서 정렬 최후에는 하나의 정렬을 출력한다.

   합병은 두 개의 배열을 비교하여, 기준에 맞는 값을 다른 배열에 저장해 나간다.
   오름차순의 경우 배열A, 배열B를 비교하여 A에 있는 값이 더 작다면 새 배열에 저장해주고, A인덱스를 증가시킨 후 A,B의 반복을 진행한다. A나 B중 하나가 모든 배열값을 새 배열에 저장할 때까지 반복하며, 전부 다 저장하지 못한 배열의 값들은 모두 새 배열의 값에 저장해준다.

   로직

   분할 과정

   1. 현재 배열을 반으로 쪼갠다. 배열의 시작 위치와, 종료 위치를 입력받아 둘을 더한 후 2를 나눠 그 위치를 기준으로 나눈다.
   2. 이를 쪼갠 배열의 크기가 0이거나 1일때 까지 반복

   합병

   1. 두 배열 A,B의 크기를 비교한다. 각각의 배열의 현재 인덱스를 i,j로 가정
   2. i에는 A배열의 시작 인덱스를 저장하고, j에는 B배열의 시작 주소를 저장한다
   3. A[i]와 B[j]를 비교한다. 오름차순의 경우 작읍 값을 새 배열 C에 저장한다. A[i]가 더 컸다면 A[i]의 값을 배열 C에 저장해주고, i의 값을 하나 증가시켜 준다.
   4. 이를 i나 j 둘중 하나가 각자 배열의 끝에 도달할 때까지 반복한다.
   5. 끝까지 저장을 못한 배열의 값을, 순서대로 전부 다 C에 저장한다.
   6. C 배열을 원래의 배열에 저장해준다.

   시간 복잡도 : 분할 - o(logN), 합병 - o(n) => o(nlogn)
   공간 복잡도 : o(2n)

5. 퀵 정렬 (Quick Sort)

   퀵 정렬 또한 분할 정복을 이용해서 정렬을 수행하는 알고리즘
   pivot point라고 기준이 되는 값 하나를 설정하여 이 값을 기준으로 작은 값을 왼쪽, 큰 값은 오른쪽으로 옮기는 방식으로 정렬을 진행. 이를 반복하여 분할한 배열의 크기가 1이 되면 배열이 모두 정렬

   로직

   1. pivot point로 잡을 배열의 값 하나를 정한다. 보통 맨 앞이나 맨 뒤, 혹은 전체 배열 값 중 중간 값이나 랜덤 값으로 정한다.
   2. 분할을 진행하기에 앞서, 비교를 진행하기 위해 가장 왼쪽 배열의 인덱스를 저장하는 left 변수, 가장 오른쪽 배열의 인덱스를 저장한 right 변수를 생성한다.
   3. right부터 비교를 진행한다. 비교는 right가 left보다 클 때만 반복하며, 비교한 배열값이 pivot point봗 크면 right 하나를 감소시키고, 비교를 반복한다. pivot point보다 작은 배열 값을 찾으면 반복을 중지한다.
   4. 그 다음 left부터 비교를 진행한다. 비교는 right가 left보다 클 때만 반복하며, 비교한 배열 값이 pivot point보다 작으면 left를 하나 증가시키고, 비교를 반복한다. pivot point보다 큰 배열 값을 찾으면 반복을 중지한다.
   5. left 인덱스의 값과 right 인덱스의 값을 바꿔준다.
   6. 3,4,5의 고ㅘ정을 left < right 가 만족할 때까지 반복한다.
   7. 위 과정이 끝나면 left의 값과 pivot point를 바꿔준다.
   8. 맨 왼쪽부터 left-1까지, left+1부터 맨 오른쪽까지로 나눠 퀵 정렬을 반복한다.

   분할과 동시에 정렬하는 알고리즘

   시간 복잡도 : o(nlogn), 최악(이미 배열 정렬되어있는 경우) - o(n^2)
   공간 복잡도 : o(n)

   일반적으로 퀵 정렬이 합병정렬보다 20%이상 빠르다

stable sort : 정렬시 같은 값의 숫자더라도 그 상대적인 위치가 유지되는 sorting 방식
ex) 삽입 정렬, 병합 정렬, 버블 정렬
unstable sort : 정렬시 같은 값의 숫자가 뒤죽박죽 섞이게 되는 sorting 방식
ex) 힙 정렬, 퀵 정렬

    선택 정렬은 구현방식에 따라 stable, unstable 달라짐
